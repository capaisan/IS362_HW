{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Predictive Analysis\n",
    "\n",
    "Using machine learning to predict if mushrooms are poisonous based on odor and gill color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to load the file from last assignment\n",
    "try:\n",
    "    df = pd.read_csv('mushroom_data_processed.csv')\n",
    "except:\n",
    "    # if not found, load from UCI\n",
    "    cols = ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
    "            'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
    "            'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
    "            'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
    "            'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
    "            'ring-type', 'spore-print-color', 'population', 'habitat']\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data'\n",
    "    temp = pd.read_csv(url, names=cols)\n",
    "    df = temp[['class', 'odor', 'gill-color']].copy()\n",
    "    df['poisonous'] = df['class'].replace({'e': 0, 'p': 1})\n",
    "    df['odor_num'] = df['odor'].replace({'a': 0, 'l': 1, 'c': 2, 'y': 3, 'f': 4, 'm': 5, 'n': 6, 'p': 7, 's': 8})\n",
    "    df['gill_num'] = df['gill-color'].replace({'k': 0, 'n': 1, 'b': 2, 'h': 3, 'g': 4, 'r': 5, 'o': 6, 'p': 7, 'u': 8, 'e': 9, 'w': 10, 'y': 11})\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dummies\n",
    "\n",
    "Converting to binary columns with get_dummies like the assignment says"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummy variables\n",
    "odor_dummies = pd.get_dummies(df['odor'], prefix='odor')\n",
    "gill_dummies = pd.get_dummies(df['gill-color'], prefix='gill')\n",
    "\n",
    "print(f\"Odor columns: {len(odor_dummies.columns)}\")\n",
    "print(f\"Gill columns: {len(gill_dummies.columns)}\")\n",
    "\n",
    "odor_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up X and y\n",
    "y = df['poisonous']\n",
    "X_odor = odor_dummies\n",
    "X_gill = gill_dummies\n",
    "X_both = pd.concat([odor_dummies, gill_dummies], axis=1)\n",
    "\n",
    "print(f\"Target: {y.shape}\")\n",
    "print(f\"Odor features: {X_odor.shape}\")\n",
    "print(f\"Gill features: {X_gill.shape}\")\n",
    "print(f\"Both features: {X_both.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "X_odor_train, X_odor_test, y_odor_train, y_odor_test = train_test_split(X_odor, y, test_size=0.3, random_state=42)\n",
    "X_gill_train, X_gill_test, y_gill_train, y_gill_test = train_test_split(X_gill, y, test_size=0.3, random_state=42)\n",
    "X_both_train, X_both_test, y_both_train, y_both_test = train_test_split(X_both, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(X_odor_train)}\")\n",
    "print(f\"Test: {len(X_odor_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odor only\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_odor_train, y_odor_train)\n",
    "pred = model.predict(X_odor_test)\n",
    "acc_odor = accuracy_score(y_odor_test, pred)\n",
    "\n",
    "# gill only\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_gill_train, y_gill_train)\n",
    "pred = model.predict(X_gill_test)\n",
    "acc_gill = accuracy_score(y_gill_test, pred)\n",
    "\n",
    "# both\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_both_train, y_both_train)\n",
    "pred = model.predict(X_both_test)\n",
    "acc_both = accuracy_score(y_both_test, pred)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"Odor: {acc_odor:.4f}\")\n",
    "print(f\"Gill: {acc_gill:.4f}\")\n",
    "print(f\"Both: {acc_both:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odor only\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_odor_train, y_odor_train)\n",
    "pred = model.predict(X_odor_test)\n",
    "acc_odor = accuracy_score(y_odor_test, pred)\n",
    "\n",
    "# gill only\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_gill_train, y_gill_train)\n",
    "pred = model.predict(X_gill_test)\n",
    "acc_gill = accuracy_score(y_gill_test, pred)\n",
    "\n",
    "# both\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_both_train, y_both_train)\n",
    "pred = model.predict(X_both_test)\n",
    "acc_both = accuracy_score(y_both_test, pred)\n",
    "\n",
    "print(\"Decision Tree:\")\n",
    "print(f\"Odor: {acc_odor:.4f}\")\n",
    "print(f\"Gill: {acc_gill:.4f}\")\n",
    "print(f\"Both: {acc_both:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odor only\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_odor_train, y_odor_train)\n",
    "pred = model.predict(X_odor_test)\n",
    "acc_odor = accuracy_score(y_odor_test, pred)\n",
    "rf_odor = model  # save for later\n",
    "\n",
    "# gill only\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_gill_train, y_gill_train)\n",
    "pred = model.predict(X_gill_test)\n",
    "acc_gill = accuracy_score(y_gill_test, pred)\n",
    "rf_gill = model  # save for later\n",
    "\n",
    "# both\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_both_train, y_both_train)\n",
    "pred = model.predict(X_both_test)\n",
    "acc_both = accuracy_score(y_both_test, pred)\n",
    "rf_both = model  # save for later\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"Odor: {acc_odor:.4f}\")\n",
    "print(f\"Gill: {acc_gill:.4f}\")\n",
    "print(f\"Both: {acc_both:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for odor\n",
    "pred = rf_odor.predict(X_odor_test)\n",
    "cm = confusion_matrix(y_odor_test, pred)\n",
    "print(\"Odor predictor:\")\n",
    "print(cm)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.title('Confusion Matrix - Odor')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for gill\n",
    "pred = rf_gill.predict(X_gill_test)\n",
    "cm = confusion_matrix(y_gill_test, pred)\n",
    "print(\"Gill predictor:\")\n",
    "print(cm)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.colorbar()\n",
    "plt.title('Confusion Matrix - Gill Color')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which features are most important in the combined model\n",
    "importances = rf_both.feature_importances_\n",
    "features = X_both.columns\n",
    "\n",
    "# make a dataframe\n",
    "imp_df = pd.DataFrame({'feature': features, 'importance': importances})\n",
    "imp_df = imp_df.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 features:\")\n",
    "print(imp_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare odor vs gill total importance\n",
    "odor_total = 0\n",
    "gill_total = 0\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    if 'odor' in feature:\n",
    "        odor_total += importances[i]\n",
    "    else:\n",
    "        gill_total += importances[i]\n",
    "\n",
    "print(f\"Odor total importance: {odor_total:.4f}\")\n",
    "print(f\"Gill total importance: {gill_total:.4f}\")\n",
    "\n",
    "plt.bar(['Odor', 'Gill'], [odor_total, gill_total])\n",
    "plt.title('Feature Importance by Type')\n",
    "plt.ylabel('Total Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a table of all results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest'],\n",
    "    'Odor': [0, 0, 0],\n",
    "    'Gill': [0, 0, 0],\n",
    "    'Both': [0, 0, 0]\n",
    "})\n",
    "\n",
    "# logistic regression\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_odor_train, y_odor_train)\n",
    "results.loc[0, 'Odor'] = accuracy_score(y_odor_test, model.predict(X_odor_test))\n",
    "model.fit(X_gill_train, y_gill_train)\n",
    "results.loc[0, 'Gill'] = accuracy_score(y_gill_test, model.predict(X_gill_test))\n",
    "model.fit(X_both_train, y_both_train)\n",
    "results.loc[0, 'Both'] = accuracy_score(y_both_test, model.predict(X_both_test))\n",
    "\n",
    "# decision tree\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_odor_train, y_odor_train)\n",
    "results.loc[1, 'Odor'] = accuracy_score(y_odor_test, model.predict(X_odor_test))\n",
    "model.fit(X_gill_train, y_gill_train)\n",
    "results.loc[1, 'Gill'] = accuracy_score(y_gill_test, model.predict(X_gill_test))\n",
    "model.fit(X_both_train, y_both_train)\n",
    "results.loc[1, 'Both'] = accuracy_score(y_both_test, model.predict(X_both_test))\n",
    "\n",
    "# random forest\n",
    "results.loc[2, 'Odor'] = accuracy_score(y_odor_test, rf_odor.predict(X_odor_test))\n",
    "results.loc[2, 'Gill'] = accuracy_score(y_gill_test, rf_gill.predict(X_gill_test))\n",
    "results.loc[2, 'Both'] = accuracy_score(y_both_test, rf_both.predict(X_both_test))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "x = [0, 1, 2]\n",
    "width = 0.25\n",
    "\n",
    "plt.bar([i - width for i in x], results['Odor'], width, label='Odor')\n",
    "plt.bar(x, results['Gill'], width, label='Gill')\n",
    "plt.bar([i + width for i in x], results['Both'], width, label='Both')\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison')\n",
    "plt.xticks(x, results['Model'])\n",
    "plt.legend()\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Odor is definitely the better predictor. It gets over 97% accuracy with all the models, and Random Forest gets it almost perfect.\n",
    "\n",
    "Gill color is okay but not as good - around 90-92% accuracy.\n",
    "\n",
    "Using both together helps a little bit but not much since odor is already so good.\n",
    "\n",
    "The feature importance chart shows odor features are way more important than gill color features.\n",
    "\n",
    "Random Forest worked best overall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
